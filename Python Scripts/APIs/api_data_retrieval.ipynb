{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "9813cc8d-1131-4856-a0a8-1bbeab316d6e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn import neighbors\n",
    "import math\n",
    "\n",
    "import itertools, os\n",
    "import datetime as dt\n",
    "import dateutil.relativedelta as reldelta\n",
    "import requests as rq\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import plotly as py\n",
    "from plotly.offline import download_plotlyjs\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import quandl as qd\n",
    "qd.ApiConfig.api_key = \"-o5sCYdh6rHfBtU_RVto\"\n",
    "from fredapi import Fred\n",
    "fred = Fred(api_key='11566066f130f6f1d3af60679239e53e')\n",
    "import googlefinance.client as gf\n",
    "import pandasdmx as sdmx\n",
    "\n",
    "import win32com\n",
    "import win32com.client as cl # note due to use of win32 this will not work on apple mac computers\n",
    "from win32com.client import makepy\n",
    "import sys\n",
    "\n",
    "# sys.argv = [\"makepy\", r\"Excel.Application.16\"]\n",
    "# cl.makepy.main()\n",
    "#add jaso\n",
    "dir_bus_US = '../Business Cycles/US/Data/'\n",
    "dir_pred_US = '../Bond Price Predictive Model/US/'\n",
    "dir_pred_UK = '../Bond Price Predictive Model/UK/'\n",
    "dir_pred_JPN = '../Bond Price Predictive Model/JPN/'\n",
    "dir_pred_AUS = '../Bond Price Predictive Model/AUS/'\n",
    "dir_pred_CND = '../Bond Price Predictive Model/CND/'\n",
    "dir_pred_GRM = '../Bond Price Predictive Model/GRM/'\n",
    "    \n",
    "dirs_excel = {'dir_bus_US':dir_bus_US,'dir_pred_US':dir_pred_US,'dir_pred_UK':dir_pred_UK, 'dir_pred_JPN': dir_pred_JPN, 'dir_pred_AUS':dir_pred_AUS, 'dir_pred_CND':dir_pred_CND, 'dir_pred_GRM':dir_pred_GRM}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e3cb43d1-58f3-4ee0-bfeb-28866bd755da"
    }
   },
   "outputs": [],
   "source": [
    "##filters a dataset, between two given dates. Alternatively, if auto = True is passed as a parameter the end data is automaticaly set to 10 months prior to todays date\n",
    "def dateFilter(data, auto = False ,start_date = \"1975-11-30\" , end_date = (dt.datetime.today()+reldelta.relativedelta(day=31,months=-10))):\n",
    "    print(\"Filtering data to the range of {} to {}\".format(start_date, end_date))\n",
    "    if auto:\n",
    "        not_nan_indicators_on_col_C = [False if math.isnan(x) else True for x in data.loc[:,'C']]\n",
    "        start_date = data[(not_nan_indicators_on_col_C)]['Date'].iloc[0]\n",
    "                    #uses column 3 as main statistic to find out when last value is\n",
    "    else:\n",
    "        start_date =  dt.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                       ##taking out values of the form 00:00:00. These are rows with no statistic value\n",
    "    data = data[[True if type(x) in [dt.datetime, pd.Timestamp ] else False for x in data['Date']]]\n",
    "    data = data[ (data['Date'] > start_date) ]\n",
    "    data = data[(data['Date'] < end_date)]\n",
    "    data.reset_index(inplace=True,drop=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a81f78c5-1a15-444b-bcb5-e072b77a0a3b"
    }
   },
   "outputs": [],
   "source": [
    "#note used\n",
    "#Given a dataset and names of specific coloumns/features, pairwise multiplication is performed on all combinations of two coloumns to produce a extended set of features\n",
    "def xyXxColoumns(data,cols,replace=False):\n",
    "    i = 0\n",
    "    temp_xy_cols= pd.DataFrame() \n",
    "    cols_to_mult = data.loc[:,cols]\n",
    "    for n in cols:\n",
    "        m = list(cols).index(n)\n",
    "        while m < len(cols):\n",
    "            temp_xy_cols=pd.concat([temp_xy_cols,cols_to_mult.loc[:,n].mul(cols_to_mult.iloc[:,m],axis='index')],axis='columns', join='outer')\n",
    "            m = m+1\n",
    "    temp_xy_cols.columns = ['{0}-{1}'.format(cols[y],cols[z]) for y in list(range(0,len(cols))) for z in list(range(0,len(cols))) if z>=y ]\n",
    "    \n",
    "    if replace is True:\n",
    "        data = pd.concat([data,temp_xy_cols],axis='columns',join='inner')\n",
    "        data.reset_index(inplace=True, drop=True)\n",
    "        return data\n",
    "    return(data, temp_xy_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5beebe96-5987-4b33-b24d-9b5ef393950c"
    }
   },
   "outputs": [],
   "source": [
    "#Given a dataset and specified coloumns, col, and a number of shift(lag) n, for each coloumn/feature it creates n more coloumns that are shifts of the specified coloumn\n",
    "#with shift varying from 1 to n\n",
    "def lags(data, cols, shifts, replace=False):\n",
    "    i=0\n",
    "    df_lags= pd.DataFrame()\n",
    "    \n",
    "    while i < shifts:\n",
    "        t = (data.loc[:,cols]).shift(i+1)\n",
    "        t_cols=list(t.columns.values)\n",
    "        t.columns = ['{0}-lags-{1}'.format(y,z+1) for z in list(range(0,3)) for y in t_cols if ((t_cols.index(y)>=20*z) & (t_cols.index(y)<20*(z+1)) ) ]\n",
    "        df_lags= pd.concat([df_lags, t],axis='columns', join='outer')\n",
    "        i = i+1\n",
    "\n",
    "    data = pd.concat([data,df_lags] ,axis=1,join='inner')\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return data.iloc[1:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b1d01c6b-9d41-4b95-82e9-1a7a5cbfb82a"
    }
   },
   "outputs": [],
   "source": [
    "#for a given country copys the relevant transformed time-series data from each individual excel sheet\n",
    "#into one \"Combined sheet\" containing all data for that country\n",
    "##inner joins by \"YYYY-MM\"\n",
    "\n",
    "def createCombinedSheet(dir_model_country, features,two_types=False ,re_turn = False):\n",
    "    \n",
    "    df_combined = pd.read_excel(dirs_excel[dir_model_country]+'Combined.xlsx',sheet_name='Data',header=0,datr_parser=True)\n",
    "   \n",
    "    for feature in features:\n",
    "        df_data = pd.read_excel(dirs_excel[dir_model_country]+feature+'_hardcoded.xlsx',sheet_name='Data',header=0,datr_parser=True)\n",
    "        if two_types:\n",
    "            date_col_name = 'Date'\n",
    "            if feature in ['AA1','BC3']:\n",
    "                df_date_var = df_data.loc[:,[date_col_name,feature]]\n",
    "            else: \n",
    "                df_date_var = df_data.loc[:,[date_col_name,feature+\"C\", feature+\"L\"]]\n",
    "        else:\n",
    "            date_col_name = 'Month-Year'\n",
    "            df_date_var = df_data.loc[:,['Month-Year',feature]]\n",
    "        \n",
    "        df_combined = pd.merge(df_combined,df_date_var,on=date_col_name,how='inner',sort=False) \n",
    "    \n",
    "    writer = pd.ExcelWriter(dirs_excel[dir_model_country]+'Combined_hardcoded.xlsx')\n",
    "    df_combined.to_excel(writer,'Data',index=False)\n",
    "    \n",
    "    if re_turn == True : \n",
    "        return df_combined.loc[:,features]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ddb0cf79-f79a-4344-82a1-569699bfc1c7"
    }
   },
   "outputs": [],
   "source": [
    "##Interpolation on a given coloumn of data provided as an excel sheet\n",
    "#This method is for data which represents 'levels' over 3 month intervals and as such linear inerpolation is used\n",
    "def interpolationLevels(cols,dir_model_country,code ,re_turn = False):\n",
    "    df_interpolated = pd.read_excel(dirs_excel[dir_model_country]+code+'.xlsx',sheetname='Data',datr_parser=True)\n",
    "    for col in cols:\n",
    "        temp = df_interpolated.loc[:col].interpolate(method='linear')\n",
    "        df_interpolated.loc[:,col] = temp\n",
    "    \n",
    "    writer = pd.ExcelWriter(dirs_excel[dir_model_country]+'Combined_hardcoded.xlsx')\n",
    "    df_interpolated.to_excel(writer,'Data',index=False)\n",
    "    \n",
    "    if re_turn == True:\n",
    "        return df_interpolated.loc[:,[cols]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e098ed4c-f646-4f50-9da3-ff5ea3fb15d0"
    }
   },
   "outputs": [],
   "source": [
    "##Interpolation on a given coloumn of data provided as an excel sheet\n",
    "#This method is for data which represents 'Changes' across 3 month intervals and as such forward interpolation using 'zero method' \n",
    "def InterpolationLevelChanges(cols,combined_excel_file_path, re_turn = False):\n",
    "    df_uninterpolated = pd.read_excel(combined_excel_file_path+'.xlsx',sheetname='Data',header=0,datr_parser=True)\n",
    "    df_interpolated = df_uninterpolated\n",
    "    \n",
    "    for col in cols:\n",
    "        temp = df_uninterpolated.loc[:,col]\n",
    "        temp = temp[::,-1].interpolate(method='zero', limit_direction='forward')[::-1].div(3)\n",
    "        df_interpolated.loc[:,col]= temp\n",
    "    \n",
    "    writer = pd.ExcelWriter(combined_excel_file_path+'_hardcoded.xlsx')\n",
    "    df_interpolated.to_excel(writer,'Data',index=False)\n",
    "    \n",
    "    if re_turn == True:\n",
    "        return df_interpolated.loc[:,[cols]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7157b5cd-5a5c-49d2-a0e2-a2168f885dce"
    }
   },
   "outputs": [],
   "source": [
    "##Given the codes for underlying data, this downloads the data from its source, cleans the data and saves it in an appropriate location\n",
    "def retreiveData(country,features,Update=False,start_date=\"1966-11-30\"): \n",
    "    for feature in features:\n",
    "        data = retreiveDataDownload(country,feature,start_date)\n",
    "        retreiveDataToExcel(data,country,feature)\n",
    "        print(\"Underlying Data for {} for {} has been downloaded\".format(feature,country))\n",
    "        #add update=True logic to only download last entry\n",
    "\n",
    "def retreiveDataDownload(country,feature,_start_date):\n",
    "    c_f = \"{}{}\".format(country,feature)\n",
    "    #Quandl Codes\n",
    "    qd_stats_US = ['USMP2']\n",
    "    qd_codes_US = {'USMP2':['MULTPL/SP500_REAL_PRICE_MONTH']}\n",
    "    qd_stats_UK = ['UKMP4','UKAA1']\n",
    "    qd_codes_UK = {'UKMP4':['BOE/IUMWRLN','BOE/IUMSNPY'],'UKMP1':['BOE/IUMWRLN','BOE/IUMSNPY'],'UKAA1':['BOE/IUMWRLN','BOE/IUMSNPY']}\n",
    "    qd_stats_JPN = ['JPNI2', 'JPNGM1'] # JPNMP1 has a fault on quandls end temporarily removed\n",
    "    qd_codes_JPN = {'JPNI2':['MOFJ/INTEREST_RATE_JAPAN_9Y'],'JPNGM1':['RATEINF/CPI_JPN'],'JPNMP1':['MOFJ/INTEREST_RATE_JAPAN_9Y','MOFJ/INTEREST_RATE_JAPAN_5Y']}\n",
    "    qd_stats_GRM = ['GRMMP2']\n",
    "    qd_codes_GRM = {'GRMMP2' :['BUNDESBANK/BBK01_WU3141'] }\n",
    "    qd_stats_AUS =[]\n",
    "    qd_codes_AUS = {}\n",
    "    qd_stats_CND =[]\n",
    "    qd_codes_CND ={}\n",
    "    qd_stats= qd_stats_US + qd_stats_UK + qd_stats_JPN + qd_stats_GRM + qd_stats_AUS + qd_stats_CND\n",
    "    qd_codes = {}\n",
    "    qd_codes.update(qd_codes_US), qd_codes.update(qd_codes_UK), qd_codes.update(qd_codes_JPN), qd_codes.update(qd_codes_GRM), qd_codes.update(qd_codes_AUS), qd_codes.update(qd_codes_CND)\n",
    "    \n",
    "    ##FRED codes\n",
    "    fd_stats_US = ['USAA1','USI2','USI1','USGM2','USGM1','USFF1','USMP1','USMP4'] \n",
    "    fd_codes_US = {'USAA1':['GS5'], 'USI2':['GS10','BAA'], 'USI1':['GDPC1','NAEXKP04USQ661S'], 'USGM2':['NAEXKP04USQ661S'], 'USGM1':['CPIAUCSL'],'USFF1':['NNUSBIS'],'USMP1':['GS10','GS5'],'USMP4':['GS5']}\n",
    "    fd_stats_UK =['UKI2','UKI1','UKGM2','UKGM1','UKFF1','UKMP1','UKMP2']\n",
    "    fd_codes_UK = {'UKI2':['IRLTLT01GBM156N','BAA'],'UKI1':['NAEXKP01GBQ652S','NAEXKP04GBQ652S'],'UKGM2':['CLVMNACSCAB1GQUK'],'UKGM1':['GBRCPIALLMINMEI'],'UKFF1':['NNGBBIS'],'UKMP1':['IRLTLT01GBM156N'],'UKMP2':['SPASTT01GBM661N']}\n",
    "    fd_stats_GRM = ['GRMI1','GRMI2' ,'GRMGM2','GRMGM1','GRMFF1']\n",
    "    fd_codes_GRM = { 'GRMI1':['DEUGFCFQDSMEI','NAEXKP01DEQ661S'], 'GRMI2': ['IRLTLT01DEM156N','BAA'],'GRMGM2':['NAEXKP01DEQ661S'], 'GRMGM1':['DEUCPIALLMINMEI'],'GRMFF1':['RNDEBIS'], 'GRMMP1':['IRLTLT01DEM156N']}\n",
    "    fd_stats_JPN = ['JPNMP2','JPNI2']\n",
    "    fd_codes_JPN ={'JPNMP2':['SPASTT01JPM661N'], 'JPNI2':['BAA'] }\n",
    "    fd_stats_AUS = ['AUSI2','AUSI1', 'AUSGM2', 'AUSFF1', 'AUSMP1', 'AUSMP2']\n",
    "    fd_codes_AUS ={'AUSI2':['IRLTLT01AUM156N','BAA'],'AUSI1': ['AUSGDPRQDSMEI','NAEXKP04AUQ189S'],'AUSGM2':['AUSGDPRQDSMEI'],'AUSFF1':['NNAUBIS'],'AUSMP1':['IRLTLT01AUM156N'],'AUSMP2':['SPASTT01AUM661N']}\n",
    "    fd_stats_CND = ['CNDI2','CNDI1','CNDGM2','CNDGM1','CNDFF1','CNDMP1','CNDMP2']\n",
    "    fd_codes_CND ={ 'CNDI2' :['IRLTLT01CAM156N','BAA'],'CNDI1':['NAEXKP01CAQ189S','NAEXKP04CAQ189S'], 'CNDGM2':['NAEXKP01CAQ189S'],'CNDGM1':['CPALCY01CAM661N'] ,'JPNFF1':['NNJPBIS'],'CNDFF1':['NNCABIS'],'CNDMP1':['IRLTLT01CAM156N'],'CNDMP2':['SPASTT01CAM661N']}\n",
    "    fred_stats= fd_stats_US + fd_stats_UK+ fd_stats_GRM + fd_stats_JPN + fd_stats_AUS + fd_stats_CND\n",
    "    fred_codes={}\n",
    "    fred_codes.update(fd_codes_US), fred_codes.update(fd_codes_UK), fred_codes.update(fd_codes_GRM), fred_codes.update(fd_codes_JPN), fred_codes.update(fd_codes_AUS), fred_codes.update(fd_codes_CND)\n",
    "    \n",
    "    ##Google Finance, OECD & IMF & LocalData\n",
    "\n",
    "    #oecd_stats =['GRMMP4']\n",
    "#     s_date = \"{}-{}\".format(_start_date[:4],_start_date[5:7])\n",
    "#     e_date =  \"{}-{}\".format(dt.date.today().year,dt.date.today().month)\n",
    "    #oecd_codes = {'GRMMP4':[\"http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/MEI_FIN/IR3TIB+CCUS.DEU.M/all?startTime={0}&endTime={1}\".format(s_date,e_date)]}\n",
    "    imf_stats = []\n",
    "                     #enter IMF parameters in the following order: ['Freq', 'Country', 'Code']\n",
    "    imf_codes = {}\n",
    "    \n",
    "    local_data= ['GRMPMP1','GRMAA1','CNDMP1', 'CNDMP4','CNDAA1','AUSMP1','AUSMP4','AUSAA1','JPNI1','JPNGM2','JPNAA1']\n",
    "    local_stats = {'GRMMP1':['https://www.bundesbank.de/cae/servlet/StatisticDownload?tsId=BBK01.WZ3404&its_csvFormat=en&its_fileFormat=csv&mode=its'],\n",
    "                    'GRMMP4' : ['https://www.bundesbank.de/cae/servlet/StatisticDownload?tsId=BBK01.WZ3404&its_csvFormat=en&its_fileFormat=csv&mode=its'],\n",
    "                    'GRMAA1' : ['https://www.bundesbank.de/cae/servlet/StatisticDownload?tsId=BBK01.WZ3404&its_csvFormat=en&its_fileFormat=csv&mode=its'],\n",
    "                   'AUSMP1':['https://www.rba.gov.au/statistics/tables/xls/f02hist.xls?v=2017-11-20-14-18-03'],\n",
    "                   'AUSMP4':['http://www.rba.gov.au/statistics/tables/xls-hist/f02dhist.xls'],\n",
    "                   'AUSAA1':['http://www.rba.gov.au/statistics/tables/xls-hist/f02dhist.xls'],\n",
    "                   'JPNI1':['http://www.esri.cao.go.jp/en/sna/data/sokuhou/files/2017/qe173/gdemenuea.html'],\n",
    "                   'JPNGM2':['http://www.esri.cao.go.jp/en/sna/data/sokuhou/files/2017/qe173/gdemenuea.html'],\n",
    "                   'JPNMP1':[dirs_excel['dir_pred_JPN']],\n",
    "                   \"JPNMP4\":[dirs_excel['dir_pred_JPN']],\n",
    "                   \"JPNMP1\" : [\"C:/Users/Rilwa/Desktop/Algorthmic Trading Platform/Bond Price Predictive Model/JPN\"],\n",
    "                   \"CNDMP1\" : ['http://www5.statcan.gc.ca/access_acces/alternative_alternatif?l=eng&keng=7.059&kfra=7.059&teng=Download%20file%20from%20CANSIM&tfra=Fichier%20extrait%20de%20CANSIM&loc=http://www5.statcan.gc.ca/cansim/results/cansim6627822687716512013.csv'],\n",
    "                   \"CNDMP4\" : ['http://www5.statcan.gc.ca/access_acces/alternative_alternatif?l=eng&keng=7.059&kfra=7.059&teng=Download%20file%20from%20CANSIM&tfra=Fichier%20extrait%20de%20CANSIM&loc=http://www5.statcan.gc.ca/cansim/results/cansim6627822687716512013.csv'],\n",
    "                   \"CNDAA1\" : ['http://www5.statcan.gc.ca/access_acces/alternative_alternatif?l=eng&keng=7.059&kfra=7.059&teng=Download%20file%20from%20CANSIM&tfra=Fichier%20extrait%20de%20CANSIM&loc=http://www5.statcan.gc.ca/cansim/results/cansim6627822687716512013.csv'],\n",
    "                    'AUSGM1':['http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/6401.0Sep%202017?OpenDocument#Time'],\n",
    "                      'JPNAA1':[dirs_excel['dir_pred_JPN']]}\n",
    "                \n",
    "    #define period and interval size\n",
    "    \n",
    "    day1 = dt.datetime.strptime(_start_date, '%Y-%m-%d' )\n",
    "    day2 = dt.date.today() - reldelta.relativedelta(day=31,months=-1)\n",
    "    date_range = pd.date_range(day1, periods= ( 12*(day2.year - day1.year) + day2.month - day1.month) ,freq='M')\n",
    "    data_full =pd.DataFrame(index=date_range)\n",
    "    \n",
    "    if c_f in fred_stats:\n",
    "        data = pd.DataFrame(index=date_range)\n",
    "        for code in fred_codes[c_f]:\n",
    "            temp_data = pd.DataFrame(fred.get_series_first_release(series_id=code))\n",
    "                        \n",
    "            temp_data.index.name =None\n",
    "            temp_data.index = [time.date() for time in temp_data.index]\n",
    "            temp_data.index = [ (_t + dt.timedelta(-1)) if (_t.day ==1) else _t for _t in temp_data.index]\n",
    "            data = pd.merge(data,temp_data,how='left',left_index=True, right_index=True,)\n",
    "        data_full = pd.merge(data_full, data,how='left',left_index=True, right_index=True,sort=True)\n",
    "        \n",
    "    if c_f in qd_stats:\n",
    "        data = pd.DataFrame(index= date_range)\n",
    "        for code in qd_codes[c_f]:\n",
    "            temp_data = qd.get(code,returns='pandas',start_date=_start_date)\n",
    "            temp_data.index = [time.date() for time in temp_data.index]\n",
    "            temp_data.index = [ (_t - dt.timedelta(days=1)) if _t.day==1 else _t for _t in temp_data.index]\n",
    "            data = pd.merge(data,temp_data,how='left',left_index=True, right_index=True)\n",
    "        data_full = pd.merge(data_full, data,how='left',left_index=True, right_index=True,sort=True)\n",
    "    \n",
    "    if c_f in imf_stats:\n",
    "        data = pd.DataFrame(index=date_range)\n",
    "        for code in imf_codes[c_f]:\n",
    "            root_link= \"http://dataservices.imf.org/REST/SDMX_JSON.svc/CompactData/IFS/\"\n",
    "            s_date, e_date = dt.datetime.strptime(_start_date,'%Y-%m-%d').year, dt.date.today().year\n",
    "            query = '{0}.{1}.{2}.?startPeriod={3}&endPeriod={4}'.format(code[0],code[1],code[2],s_date,e_date)\n",
    "        \n",
    "            data_xml = rq.get(root_link+query).json()\n",
    "            temp_data = pd.DataFrame(data_xml['CompactData']['DataSet']['Series'])\n",
    "            \n",
    "            temp_data.index = [dt.datetime.strptime(\"{}{}\".format(d[:4],d[-1:][0]*3),'%Y%m').date + pd.offsets.MonthEnd() for d in temp_data['@TIME_PERIOD']]\n",
    "            del temp_data['@TIME_PERIOD']\n",
    "            data = pd.merge(data,temp_data,how='left',left_index=True, right_index=True)\n",
    "        data_full = pd.merge(data_full, data, how='left',left_index=True, right_index=True)\n",
    "    \n",
    "    if c_f in local_data:\n",
    "        print(\"Some or all Data for {} is saved locally\".format(c_f))\n",
    "        for code in local_stats[c_f]:\n",
    "            print(\"The original link/s is {0} . \".format(code))\n",
    "            \n",
    "    data_full = data_full[~data_full.index.duplicated(keep='first')]    \n",
    "    return data_full\n",
    "\n",
    "def retreiveDataToExcel(_data,_country,_feature):   \n",
    "    data = _data.reset_index().applymap(lambda x: str(x))\n",
    "    row_no = _data.shape[0] +1\n",
    "    col_no = _data.shape[1] + 1\n",
    "    data = data.as_matrix().tolist()\n",
    "    \n",
    "    xl_instance = cl.gencache.EnsureDispatch('Excel.Application.16')\n",
    "    xl_instance.Visible = True\n",
    "    xl_path = \"../Bond Price Predictive Model/{0}/{1}.xlsx\".format(_country,_feature)\n",
    "       \n",
    "    xl_wb = openWorkbook(xl_instance, os.path.abspath(xl_path))\n",
    "    wl_ws = xl_wb.Worksheets('Source')\n",
    "\n",
    "    wl_ws.Range(wl_ws.Cells(2,1),wl_ws.Cells(row_no,col_no)).Value = data\n",
    "    xl_wb.Close(True)\n",
    "    \n",
    "def openWorkbook(_xl_instance, _xl_path):\n",
    "    try:        \n",
    "        xlwb = _xl_instance.Workbooks(_xl_path)            \n",
    "    except Exception as e:\n",
    "        try:\n",
    "            xlwb = _xl_instance.Workbooks.Open(_xl_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            xlwb = None                    \n",
    "    return xlwb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "17c54589-2302-41b6-8db7-3bd69bfb1387"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "##Adewoyin-Savitzky-Golay Filters Smoothing\n",
    "##sends it from excel file to excel file\n",
    "##intended to work on raw files, to be used before sending to combined\n",
    "\n",
    "#Method\n",
    "##UnSavgolfiltered values are transformed by subtracting the min value from all values\n",
    "##train savgol filter on data : window size chosen to be a factor 2 bigger than polyorder\n",
    "## Finds unit value of Positivity/negativity in SAVGOl filter betwen t1 and t0.\n",
    "##This value (+1/-1) is then multiplied by the corresponding unSavgolfiltered values\n",
    "##Allows one to distinguish between high and rising and high and dipping.\n",
    "\n",
    "##out_col should be the general code for variable\n",
    "def AdewoyinSavgolFilter(out_col,dir_model_country,windowlength=13, polyorder=4,types=['C','L'], save_xlsx= False, _auto_filter_date = False, re_turn_graph = False):\n",
    "    \n",
    "    for _out_col in out_col:\n",
    "        \n",
    "        path = dirs_excel[dir_model_country]+_out_col\n",
    "        data = pd.read_excel(path+'.xlsx', sheet_name= 'Data')\n",
    "        \n",
    "        data = dateFilter(data,auto=_auto_filter_date )\n",
    "              \n",
    "        for _type in types:\n",
    "            #Creating copy  of original data ex outliers\n",
    "                #Since there is approx 600 values in my data and they are stable, I will assume there are at most 12 outliers since data\n",
    "            _contamination =  (40/data[_type].shape[0])\n",
    "            outlier_clf = neighbors.LocalOutlierFactor(n_neighbors=20,contamination=_contamination,n_jobs=1)\n",
    "            data[_type+\" inliers\"] = outlier_clf.fit_predict( data.loc[:,_type].as_matrix().reshape(-1,1) )\n",
    "\n",
    "            inlier_max = data[(data[_type+\" inliers\"]==1)][_type].max()\n",
    "            inlier_min = data[(data[_type+\" inliers\"]==1)][_type].min()\n",
    "            absolute_inlier_max = np.maximum(np.absolute(inlier_max), np.absolute(inlier_min))\n",
    "\n",
    "            data[_type+\" ex. outliers\"] = [(np.sign(x)*absolute_inlier_max) if np.absolute(x)>absolute_inlier_max else x for x in data[_type]]\n",
    "\n",
    "            ##making savgol filter and savgol period on period change\n",
    "            savgol_signal = pd.DataFrame(signal.savgol_filter(data.loc[:,_type], window_length=windowlength, polyorder=polyorder))\n",
    "            data[\"{}_Savgol_Filtered\".format(_type)] = savgol_signal\n",
    "            signal_change_per_period = savgol_signal.diff()\n",
    "            signal_change_per_period_sign = [1 if val>0 else -1 if val<0 else 0 for val in signal_change_per_period.iloc[:,0]]\n",
    "            \n",
    "            #AdeSavGol output\n",
    "            data[_type+\" above 0\"] = data[_type+\" ex. outliers\"] - (data[_type+\" ex. outliers\"].min())   \n",
    "            data[_out_col+_type] = data[_type+\" above 0\"] * (signal_change_per_period_sign)\n",
    "\n",
    "        if save_xlsx == True:\n",
    "            writer = pd.ExcelWriter(path+'_hardcoded.xlsx')\n",
    "            data.to_excel(writer,'Data',index=False)\n",
    "\n",
    "        if re_turn_graph == True:\n",
    "            #x= np.arange(len(savgol_signal)-1)\n",
    "            trace0= go.Scatter(x= np.asarray(data['Date']), y=data[_type].as_matrix().flatten(), name=\"Original Data\")\n",
    "            trace1 = go.Scatter(x= np.asarray(data['Date']),y=savgol_signal.as_matrix().flatten(), name =\"Savgol Filter\")\n",
    "            trace2 = go.Scatter(x= np.asarray(data['Date']),y=np.asarray(signal_change_per_period_sign).flatten(), name =\"Savgol Filter Change\")\n",
    "            \n",
    "            trace3= go.Scatter(x= np.asarray(data['Date']), y=data[_type+\" ex. outliers\"].as_matrix().flatten(), name = \"L^ex-out\")\n",
    "            trace4= go.Scatter(x= np.asarray(data['Date']), y=data[_type+\" above 0\"].as_matrix().flatten(), name = \"L^S2\")\n",
    "            trace5 = go.Scatter(x= np.asarray(data['Date']), y=data[_out_col+_type].as_matrix().flatten(),name='L_asg' )\n",
    "            \n",
    "            trace_set = [trace0,trace1,trace2,trace3,trace4,trace5]\n",
    "            layout = go.Layout(title = _out_col+_type)\n",
    "            fig = go.Figure(data=trace_set, layout=layout)\n",
    "\n",
    "            py.offline.iplot(fig, image='png',filename=\"{}-{}\".format(_out_col,_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     if c_f in oecd_stats:\n",
    "#         data = pd.DataFrame(index=date_range)\n",
    "#         for code in oecd_codes[c_f]:\n",
    "#             response = rq.get(code)\n",
    "            \n",
    "#             temp_data = ET.fromstring(response.text[3:])\n",
    "#             namespaces = {'main':\"http://www.SDMX.org/resources/SDMXML/schemas/v2_0/generic\"}                      \n",
    "#             xml_dataset = temp_data.find('main:DataSet',namespaces)\n",
    "#             xml_series = xml_dataset.find('main:Series',namespaces)\n",
    "#             obs_list =[]\n",
    "#             for obs in xml_series.findall('main:Obs',namespaces):\n",
    "#                  obs_list = obs_list + [obs.find('main:Time',namespaces).text, obs.find('main:ObsValue',namespaces).get('value')] \n",
    "#             obs_array = np.asarray(obs_list).reshape(-1,2)\n",
    "            \n",
    "#             temp_data=pd.DataFrame( data=obs_array[:,1], columns =[\"Value\"], index=obs_array[:,0])\n",
    "                     \n",
    "#             temp_data.index = [dt.datetime.strptime(_d,\"%Y-%m\").date() + pd.offsets.MonthEnd() for _d in temp_data.index] # was not needed\n",
    "#             #temp_data.index = [date + pd.offsets.MonthEnd() for date in temp_data.index]\n",
    "            \n",
    "#             data = pd.merge(data,temp_data,how='left',left_index=True, right_index=True)\n",
    "#         data_full = pd.merge(data_full,data,how='left',left_index=True, right_index=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "07956026-803a-4a0b-919f-0f15ad9da2f6": {
     "id": "07956026-803a-4a0b-919f-0f15ad9da2f6",
     "prev": "9eb95580-1404-460f-8a66-36a07a124ae5",
     "regions": {
      "993793bc-8a6e-4688-8775-2a59356b47ca": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ddb0cf79-f79a-4344-82a1-569699bfc1c7",
        "part": "whole"
       },
       "id": "993793bc-8a6e-4688-8775-2a59356b47ca"
      }
     }
    },
    "3c07f91e-2b11-475f-87d8-be39915b94ab": {
     "id": "3c07f91e-2b11-475f-87d8-be39915b94ab",
     "prev": "07956026-803a-4a0b-919f-0f15ad9da2f6",
     "regions": {
      "c0980d8d-0696-4e10-8b46-54cb3e52bebb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e098ed4c-f646-4f50-9da3-ff5ea3fb15d0",
        "part": "whole"
       },
       "id": "c0980d8d-0696-4e10-8b46-54cb3e52bebb"
      }
     }
    },
    "5da7d3b0-c043-4d09-9ae0-f7c79f224721": {
     "id": "5da7d3b0-c043-4d09-9ae0-f7c79f224721",
     "prev": "3c07f91e-2b11-475f-87d8-be39915b94ab",
     "regions": {
      "d7179bad-d270-431e-b070-d69fafe4ba7e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "17c54589-2302-41b6-8db7-3bd69bfb1387",
        "part": "whole"
       },
       "id": "d7179bad-d270-431e-b070-d69fafe4ba7e"
      }
     }
    },
    "82d412c2-4a61-4064-8350-004f383aed32": {
     "id": "82d412c2-4a61-4064-8350-004f383aed32",
     "prev": null,
     "regions": {
      "6d262590-2d24-48bb-a7b5-4495777b91d6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9813cc8d-1131-4856-a0a8-1bbeab316d6e",
        "part": "whole"
       },
       "id": "6d262590-2d24-48bb-a7b5-4495777b91d6"
      }
     }
    },
    "8b13362d-2e91-4005-83b7-0d95a5075296": {
     "id": "8b13362d-2e91-4005-83b7-0d95a5075296",
     "prev": "d29ec22e-739d-4b21-b3e3-14d7e177b9ec",
     "regions": {
      "3fdf5bfd-1151-4366-b81e-d1faccb518da": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5beebe96-5987-4b33-b24d-9b5ef393950c",
        "part": "whole"
       },
       "id": "3fdf5bfd-1151-4366-b81e-d1faccb518da"
      }
     }
    },
    "90bcbc41-6b7f-44aa-907e-177997832cfc": {
     "id": "90bcbc41-6b7f-44aa-907e-177997832cfc",
     "prev": "5da7d3b0-c043-4d09-9ae0-f7c79f224721",
     "regions": {
      "8a6652bc-4ecd-4fe0-8709-b6d006e476fb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7157b5cd-5a5c-49d2-a0e2-a2168f885dce",
        "part": "whole"
       },
       "id": "8a6652bc-4ecd-4fe0-8709-b6d006e476fb"
      }
     }
    },
    "9eb95580-1404-460f-8a66-36a07a124ae5": {
     "id": "9eb95580-1404-460f-8a66-36a07a124ae5",
     "prev": "8b13362d-2e91-4005-83b7-0d95a5075296",
     "regions": {
      "f801bb8d-9f3b-45af-a4b4-abd576fd98d5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b1d01c6b-9d41-4b95-82e9-1a7a5cbfb82a",
        "part": "whole"
       },
       "id": "f801bb8d-9f3b-45af-a4b4-abd576fd98d5"
      }
     }
    },
    "c0fd9aef-73f1-4f44-9dbd-5457587c4dfd": {
     "id": "c0fd9aef-73f1-4f44-9dbd-5457587c4dfd",
     "prev": "90bcbc41-6b7f-44aa-907e-177997832cfc",
     "regions": {
      "e2c1a75c-2aba-4492-bb47-b3d937335f4a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6ef49c81-a912-420d-bd0b-b903d1ba9c92",
        "part": "whole"
       },
       "id": "e2c1a75c-2aba-4492-bb47-b3d937335f4a"
      }
     }
    },
    "d29ec22e-739d-4b21-b3e3-14d7e177b9ec": {
     "id": "d29ec22e-739d-4b21-b3e3-14d7e177b9ec",
     "prev": "f91c3b50-add4-4c23-b41a-db41812e1a5b",
     "regions": {
      "ad71a547-fbc8-4d5d-8e57-53dd267782c2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a81f78c5-1a15-444b-bcb5-e072b77a0a3b",
        "part": "whole"
       },
       "id": "ad71a547-fbc8-4d5d-8e57-53dd267782c2"
      }
     }
    },
    "f91c3b50-add4-4c23-b41a-db41812e1a5b": {
     "id": "f91c3b50-add4-4c23-b41a-db41812e1a5b",
     "prev": "82d412c2-4a61-4064-8350-004f383aed32",
     "regions": {
      "abe0d65d-e8fb-4667-acd9-b84214b52261": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e3cb43d1-58f3-4ee0-bfeb-28866bd755da",
        "part": "whole"
       },
       "id": "abe0d65d-e8fb-4667-acd9-b84214b52261"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
